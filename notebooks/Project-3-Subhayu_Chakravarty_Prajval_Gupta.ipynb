{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMAWx64-2KXW"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A32xdnkv2N6w"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQZaahFL2Ybe"
   },
   "outputs": [],
   "source": [
    "# Defining class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uC9-P6jI2Y3J"
   },
   "outputs": [],
   "source": [
    "# Taking data and splitting into Train and Test samples\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "cSNuXU_c3Jta",
    "outputId": "6b55a702-39af-4923-9b75-410589e6ad3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7d106021d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYK8MyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing one element of training set\n",
    "plt.imshow(X_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mn4vn_83J4-"
   },
   "outputs": [],
   "source": [
    "# Converting class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whsNkII13J79"
   },
   "outputs": [],
   "source": [
    "# Normalizing training and test datasets\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-H7BQie23J1z"
   },
   "outputs": [],
   "source": [
    "# Initializing Neural Network Model\n",
    "model = Sequential()\n",
    "# Adding 5 convolutional layers of 100 hidden units, using activation function=relu - Rectified Linear Unit\n",
    "model.add(Conv2D(100,(3,3), input_shape = X_train.shape[1:],padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(100,(3,3),padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(100,(3,3),padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(100,(3,3),padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(100,(3,3),padding='same', activation = 'relu'))\n",
    "# Flattening the input\n",
    "model.add(Flatten())\n",
    "# Adding a dense layer for the 10 classes,  element-wise activation function applied in this layer\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9nf_FAc3J-2"
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "BOXRAXu67t4F",
    "outputId": "437914b7-915f-4355-e3ca-a1a2b847f7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.6102 - acc: 0.4194 - val_loss: 1.3000 - val_acc: 0.5330\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.1449 - acc: 0.5964 - val_loss: 1.0154 - val_acc: 0.6452\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.9234 - acc: 0.6778 - val_loss: 0.9139 - val_acc: 0.6792\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.7895 - acc: 0.7279 - val_loss: 0.8529 - val_acc: 0.7037\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6898 - acc: 0.7613 - val_loss: 0.8031 - val_acc: 0.7209\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5959 - acc: 0.7929 - val_loss: 0.8246 - val_acc: 0.7222\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5107 - acc: 0.8232 - val_loss: 0.8057 - val_acc: 0.7340\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4451 - acc: 0.8451 - val_loss: 0.8602 - val_acc: 0.7290\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3791 - acc: 0.8677 - val_loss: 0.8565 - val_acc: 0.7314\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3354 - acc: 0.8810 - val_loss: 0.9231 - val_acc: 0.7258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d287198d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model on CPU time : 640 sec time taken\n",
    "model.fit(X_train, y_train, batch_size=300, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "vFkyc9De7yzm",
    "outputId": "a843b769-416d-488c-a488-f668667aac7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 473us/step\n",
      "Test loss: 0.92\n",
      "Test accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Displaying Testing accuracy\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61-NogSlLc0f"
   },
   "source": [
    "### Task 1: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BN2GO2gl7yxA"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             samplewise_center=False, \n",
    "                             featurewise_std_normalization=False, \n",
    "                             rotation_range=45, # 45 degrees rotation of image\n",
    "                             width_shift_range=0.2, # shifting images as fraction of total width\n",
    "                             height_shift_range=0.2, # shifting images as fraction of total height\n",
    "                             horizontal_flip=True) # Flipping image horizontally\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: CNN + Timing taken - GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "848xjYAx7y2a",
    "outputId": "bb05089d-65be-4385-d411-048d35ad31e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 1.8751 - acc: 0.3117 - val_loss: 1.5030 - val_acc: 0.4530\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 1.5944 - acc: 0.4194 - val_loss: 1.3156 - val_acc: 0.5229\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.4752 - acc: 0.4650 - val_loss: 1.2299 - val_acc: 0.5556\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.3984 - acc: 0.4948 - val_loss: 1.2287 - val_acc: 0.5620\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.3292 - acc: 0.5206 - val_loss: 1.1264 - val_acc: 0.5925\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.2916 - acc: 0.5361 - val_loss: 1.0581 - val_acc: 0.6245\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 41s 83ms/step - loss: 1.2490 - acc: 0.5530 - val_loss: 1.1682 - val_acc: 0.6004\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.2151 - acc: 0.5631 - val_loss: 1.0154 - val_acc: 0.6414\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 1.1883 - acc: 0.5757 - val_loss: 1.0169 - val_acc: 0.6364\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.1642 - acc: 0.5860 - val_loss: 0.9919 - val_acc: 0.6484\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.1460 - acc: 0.5904 - val_loss: 1.0777 - val_acc: 0.6250\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.1337 - acc: 0.5961 - val_loss: 1.0393 - val_acc: 0.6302\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 1.1185 - acc: 0.6036 - val_loss: 0.9868 - val_acc: 0.6553\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 1.0996 - acc: 0.6100 - val_loss: 0.9002 - val_acc: 0.6841\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0846 - acc: 0.6150 - val_loss: 0.9495 - val_acc: 0.6661\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0765 - acc: 0.6181 - val_loss: 0.9729 - val_acc: 0.6620\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 41s 83ms/step - loss: 1.0680 - acc: 0.6218 - val_loss: 0.9013 - val_acc: 0.6811\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 41s 83ms/step - loss: 1.0583 - acc: 0.6239 - val_loss: 0.9373 - val_acc: 0.6740\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0507 - acc: 0.6268 - val_loss: 0.9340 - val_acc: 0.6723\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 1.0346 - acc: 0.6344 - val_loss: 0.9731 - val_acc: 0.6650\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 1.0251 - acc: 0.6351 - val_loss: 0.9458 - val_acc: 0.6705\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0248 - acc: 0.6360 - val_loss: 1.0063 - val_acc: 0.6587\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0134 - acc: 0.6398 - val_loss: 0.9299 - val_acc: 0.6717\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0018 - acc: 0.6454 - val_loss: 0.8837 - val_acc: 0.6922\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 1.0013 - acc: 0.6460 - val_loss: 0.9642 - val_acc: 0.6753\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.9916 - acc: 0.6504 - val_loss: 0.9144 - val_acc: 0.6886\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 0.9825 - acc: 0.6531 - val_loss: 1.0445 - val_acc: 0.6478\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.9878 - acc: 0.6526 - val_loss: 0.9180 - val_acc: 0.6842\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9749 - acc: 0.6561 - val_loss: 0.9285 - val_acc: 0.6882\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9731 - acc: 0.6575 - val_loss: 0.8625 - val_acc: 0.7014\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 41s 83ms/step - loss: 0.9679 - acc: 0.6601 - val_loss: 0.8871 - val_acc: 0.6978\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9604 - acc: 0.6614 - val_loss: 0.9384 - val_acc: 0.6904\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 0.9510 - acc: 0.6623 - val_loss: 0.8636 - val_acc: 0.7031\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9510 - acc: 0.6658 - val_loss: 0.8631 - val_acc: 0.7042\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 41s 83ms/step - loss: 0.9451 - acc: 0.6671 - val_loss: 0.8964 - val_acc: 0.6951\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9472 - acc: 0.6644 - val_loss: 0.8774 - val_acc: 0.7002\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.9404 - acc: 0.6686 - val_loss: 0.8290 - val_acc: 0.7167\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9359 - acc: 0.6701 - val_loss: 0.8402 - val_acc: 0.7087\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9278 - acc: 0.6733 - val_loss: 0.8688 - val_acc: 0.6981\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9253 - acc: 0.6747 - val_loss: 0.8648 - val_acc: 0.6985\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 0.9246 - acc: 0.6744 - val_loss: 0.8335 - val_acc: 0.7171\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 0.9212 - acc: 0.6750 - val_loss: 0.8555 - val_acc: 0.7124\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9142 - acc: 0.6794 - val_loss: 0.8436 - val_acc: 0.7164\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9202 - acc: 0.6760 - val_loss: 0.8189 - val_acc: 0.7200\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9113 - acc: 0.6779 - val_loss: 0.8975 - val_acc: 0.7021\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.9067 - acc: 0.6794 - val_loss: 0.8342 - val_acc: 0.7117\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9167 - acc: 0.6775 - val_loss: 0.8131 - val_acc: 0.7193\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9105 - acc: 0.6789 - val_loss: 0.7707 - val_acc: 0.7308\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 41s 81ms/step - loss: 0.9024 - acc: 0.6834 - val_loss: 0.8252 - val_acc: 0.7220\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 41s 82ms/step - loss: 0.9042 - acc: 0.6831 - val_loss: 0.7744 - val_acc: 0.7328\n",
      "\n",
      "\n",
      "CNN: Time to run on Augmented Data = 3302.960688528 sec\n"
     ]
    }
   ],
   "source": [
    "#CNN on augmented data GPU\n",
    "\n",
    "#Taking time\n",
    "t0 = time.process_time()\n",
    "\n",
    "# Fitting model on Generator data\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=X_train.shape[0]//100,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4\n",
    "                   )\n",
    "\n",
    "t1 = time.process_time()\n",
    "\n",
    "total = t1-t0\n",
    "print(\"\\n\\nCNN: Time to run on Augmented Data = \"+str(total) +\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gtkpzI317y5I",
    "outputId": "1091d5f9-d951-4e70-dbd9-65f388c74d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 479us/step\n",
      "Test accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Displaying Testing accuracy\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mjp8uVh8LiHv"
   },
   "source": [
    "### Task 2: CNN + Timing taken - TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JgQw0CY55hF5",
    "outputId": "8c4c9cfe-a486-4e5b-bf06-55e7acf27317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 1.8591 - acc: 0.3207 - val_loss: 1.6206 - val_acc: 0.4308\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.6142 - acc: 0.4125 - val_loss: 1.5929 - val_acc: 0.4656\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.4891 - acc: 0.4621 - val_loss: 1.2778 - val_acc: 0.5427\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.3765 - acc: 0.5069 - val_loss: 1.3337 - val_acc: 0.5350\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.3090 - acc: 0.5300 - val_loss: 1.1972 - val_acc: 0.5852\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.2536 - acc: 0.5529 - val_loss: 1.1210 - val_acc: 0.6181\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.2019 - acc: 0.5723 - val_loss: 1.1144 - val_acc: 0.6202\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.1681 - acc: 0.5827 - val_loss: 1.0451 - val_acc: 0.6394\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.1384 - acc: 0.5959 - val_loss: 1.0918 - val_acc: 0.6309\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.1035 - acc: 0.6089 - val_loss: 0.9668 - val_acc: 0.6682\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.0795 - acc: 0.6200 - val_loss: 1.0070 - val_acc: 0.6560\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.0631 - acc: 0.6253 - val_loss: 1.0892 - val_acc: 0.6392\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.0371 - acc: 0.6362 - val_loss: 1.0585 - val_acc: 0.6639\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.0185 - acc: 0.6411 - val_loss: 1.0297 - val_acc: 0.6539\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 1.0064 - acc: 0.6447 - val_loss: 0.9877 - val_acc: 0.6747\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9991 - acc: 0.6482 - val_loss: 0.9630 - val_acc: 0.6791\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9723 - acc: 0.6578 - val_loss: 0.9575 - val_acc: 0.6856\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9634 - acc: 0.6631 - val_loss: 0.9348 - val_acc: 0.6854\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9571 - acc: 0.6648 - val_loss: 0.9459 - val_acc: 0.6893\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9415 - acc: 0.6713 - val_loss: 0.9889 - val_acc: 0.6770\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9330 - acc: 0.6732 - val_loss: 0.9474 - val_acc: 0.6825\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9262 - acc: 0.6745 - val_loss: 0.8814 - val_acc: 0.7036\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9134 - acc: 0.6790 - val_loss: 0.9258 - val_acc: 0.6910\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9085 - acc: 0.6832 - val_loss: 0.9327 - val_acc: 0.6924\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.9035 - acc: 0.6856 - val_loss: 0.9036 - val_acc: 0.6991\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8901 - acc: 0.6895 - val_loss: 0.8970 - val_acc: 0.7070\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8858 - acc: 0.6892 - val_loss: 0.8763 - val_acc: 0.7047\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8731 - acc: 0.6946 - val_loss: 0.9559 - val_acc: 0.6890\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8727 - acc: 0.6946 - val_loss: 0.9230 - val_acc: 0.7010\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8698 - acc: 0.6947 - val_loss: 0.8606 - val_acc: 0.7149\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8604 - acc: 0.6977 - val_loss: 0.8724 - val_acc: 0.7154\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8594 - acc: 0.7017 - val_loss: 0.8943 - val_acc: 0.7045\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8417 - acc: 0.7039 - val_loss: 0.8987 - val_acc: 0.7129\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8524 - acc: 0.7040 - val_loss: 0.9348 - val_acc: 0.7027\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8341 - acc: 0.7089 - val_loss: 0.8584 - val_acc: 0.7217\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8362 - acc: 0.7087 - val_loss: 0.8723 - val_acc: 0.7165\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 0.8252 - acc: 0.7126 - val_loss: 0.9033 - val_acc: 0.7074\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 0.8298 - acc: 0.7107 - val_loss: 0.8376 - val_acc: 0.7246\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 0.8241 - acc: 0.7118 - val_loss: 0.8776 - val_acc: 0.7204\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8246 - acc: 0.7121 - val_loss: 0.8874 - val_acc: 0.7083\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8174 - acc: 0.7156 - val_loss: 0.8305 - val_acc: 0.7266\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8120 - acc: 0.7157 - val_loss: 0.8692 - val_acc: 0.7194\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8160 - acc: 0.7148 - val_loss: 0.9691 - val_acc: 0.7047\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 0.8071 - acc: 0.7194 - val_loss: 0.8543 - val_acc: 0.7234\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 0.8069 - acc: 0.7178 - val_loss: 0.9555 - val_acc: 0.7021\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 0.8038 - acc: 0.7210 - val_loss: 0.8390 - val_acc: 0.7273\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 72s 143ms/step - loss: 0.7968 - acc: 0.7212 - val_loss: 0.8411 - val_acc: 0.7268\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 72s 143ms/step - loss: 0.7936 - acc: 0.7214 - val_loss: 0.8699 - val_acc: 0.7260\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 72s 143ms/step - loss: 0.7939 - acc: 0.7258 - val_loss: 0.8013 - val_acc: 0.7362\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 72s 143ms/step - loss: 0.7907 - acc: 0.7243 - val_loss: 0.9338 - val_acc: 0.7129\n",
      "\n",
      "\n",
      "CNN: TPU Time to run on Augmented Data = 4514.851841488 sec\n"
     ]
    }
   ],
   "source": [
    "#CNN on augmented data TPU\n",
    "\n",
    "#Taking time\n",
    "t0 = time.process_time()\n",
    "\n",
    "# Fitting model on Generator data\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=X_train.shape[0]//100,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4\n",
    "                   )\n",
    "\n",
    "t1 = time.process_time()\n",
    "\n",
    "total = t1-t0\n",
    "print(\"\\n\\nCNN: TPU Time to run on Augmented Data = \"+str(total) +\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_S2D9l7LteX"
   },
   "source": [
    "### Task 2: LSTM + Timing taken - GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "TTPalBYexqZw",
    "outputId": "bf7f67ee-4939-45b7-a764-10e4502dcbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (1000, 1, 1024)           16781312  \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (1000, 1024)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (1000, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 25,184,266\n",
      "Trainable params: 25,184,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reshaping X_train and test for LSTM\n",
    "X_train=np.asarray(X_train.flatten()).reshape(50000,1,3072)\n",
    "X_test=np.asarray(X_test.flatten()).reshape(10000,1,3072)\n",
    "\n",
    "# Initializing model sequence\n",
    "model = Sequential()\n",
    "\n",
    "# Two LSTM layers with 1024 hidden units\n",
    "model.add(layers.LSTM(1024, batch_input_shape=(1000,1, 3072), return_sequences=True, dropout=0.2))\n",
    "model.add(layers.LSTM(1024))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQ7dmMqLxqc4"
   },
   "outputs": [],
   "source": [
    "# Compiling sequential LSTM model\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "Ut9e_H-ajcqh",
    "outputId": "a07b2d48-12db-4080-a309-58a055708a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 2.2938 - acc: 0.1257 - val_loss: 2.2635 - val_acc: 0.1846\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.2695 - acc: 0.1791 - val_loss: 2.2295 - val_acc: 0.2165\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.2456 - acc: 0.2053 - val_loss: 2.1967 - val_acc: 0.2353\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.2204 - acc: 0.2275 - val_loss: 2.1645 - val_acc: 0.2505\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.1946 - acc: 0.2413 - val_loss: 2.1369 - val_acc: 0.2537\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.1703 - acc: 0.2526 - val_loss: 2.1111 - val_acc: 0.2542\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.1467 - acc: 0.2574 - val_loss: 2.0860 - val_acc: 0.2672\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.1223 - acc: 0.2671 - val_loss: 2.0627 - val_acc: 0.2728\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.1020 - acc: 0.2754 - val_loss: 2.0451 - val_acc: 0.2761\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.0820 - acc: 0.2761 - val_loss: 2.0264 - val_acc: 0.2863\n",
      "\n",
      "\n",
      "LSTM: GPU Time to run on Data = 43.666744468000616 sec\n"
     ]
    }
   ],
   "source": [
    "#LSTM on augmented data : on GPU\n",
    "\n",
    "#Taking time\n",
    "t0 = time.process_time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=1000,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4\n",
    "                   )\n",
    "\n",
    "\n",
    "t1 = time.process_time()\n",
    "\n",
    "total = t1-t0\n",
    "print(\"\\n\\nLSTM: GPU Time to run on Data = \"+str(total) +\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: LSTM + Timing taken - TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "g07SuBqS7y8C",
    "outputId": "2348bbe1-353e-4790-f4bd-3ed2a9d132b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 2.2902 - acc: 0.1344 - val_loss: 2.2635 - val_acc: 0.1942\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 2.2682 - acc: 0.1777 - val_loss: 2.2303 - val_acc: 0.2257\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 2.2459 - acc: 0.2083 - val_loss: 2.1994 - val_acc: 0.2460\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 2.2230 - acc: 0.2259 - val_loss: 2.1672 - val_acc: 0.2669\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 2.1974 - acc: 0.2448 - val_loss: 2.1360 - val_acc: 0.2713\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 2.1723 - acc: 0.2573 - val_loss: 2.1068 - val_acc: 0.2786\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 2.1468 - acc: 0.2630 - val_loss: 2.0820 - val_acc: 0.2867\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 2.1228 - acc: 0.2747 - val_loss: 2.0586 - val_acc: 0.2861\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 2.1013 - acc: 0.2764 - val_loss: 2.0392 - val_acc: 0.2910\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 2.0816 - acc: 0.2818 - val_loss: 2.0212 - val_acc: 0.2917\n",
      "\n",
      "\n",
      "LSTM: Time to run on Augmented Data = 3159.678086914 sec\n"
     ]
    }
   ],
   "source": [
    "#LSTM on augmented data : on TPU\n",
    "\n",
    "#Taking time\n",
    "t0 = time.process_time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=1000,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    workers=4\n",
    "                   )\n",
    "\n",
    "\n",
    "t1 = time.process_time()\n",
    "\n",
    "total = t1-t0\n",
    "print(\"\\n\\nLSTM: Time to run on Augmented Data = \"+str(total) +\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mnrFIl_-DA-"
   },
   "source": [
    "## Task 3: CNN and LSTM - Timing taken by CPU\n",
    "\n",
    "#### (for CNN) The estimated time taken by CPU for each epoch is ~ 40 minutes.  \n",
    "#### (for LSTM) The estimated time taken by CPU for each epoch is ~ 30 minutes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
